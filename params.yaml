train:
  batch_size: 128
  hidden_units: 64
  dropout: 0.40
  num_epochs: 10
  lr: 0.001
  conv_activation: relu